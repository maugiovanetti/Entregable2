{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304b0f3-34f6-42d4-93b0-03992a923c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las clases necesarias\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import requests\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from googletrans import Translator\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "\n",
    "# Crear una instancia de SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "# Configurar la API key de OpenWeatherMap\n",
    "api_key = \"cb3c7af6f8a3112d069b2cd42e3d2651\"\n",
    "\n",
    "# Definir las provincias de Argentina\n",
    "provincias = [\"Buenos Aires\", \"Córdoba\", \"Santa Fe\", \"Mendoza\", \"Tucumán\", \"Parana\", \"Salta\", \"Resistencia\", \"Corrientes\", \"Misiones\", \"Santiago del Estero\", \"San Juan\", \"San Salvador de Jujuy\", \"Viedma\", \"Formosa\", \"Neuquén\", \"Rawson\", \"San Luis\", \"Catamarca\", \"La Rioja, AR\", \"Santa Rosa, AR\", \"Rio Gallegos\", \"Ushuaia\"]\n",
    "# Crear una lista para almacenar los datos del clima de cada provincia\n",
    "datos_clima = []\n",
    "\n",
    "\n",
    "#  Crea el traductor\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Obtener el clima para cada provincia\n",
    "for provincia in provincias:\n",
    "    # Realizar la solicitud a la API de clima y obtener los datos en formato JSON\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={provincia}&appid={api_key}&units=metric\"\n",
    "    respuesta = requests.get(url)\n",
    "    data = respuesta.json()\n",
    "    \n",
    "    # Extraer los datos necesarios de la respuesta JSON y crear un objeto Row\n",
    "    dato_clima = Row(\n",
    "        ID=len(datos_clima)+1,\n",
    "        longitud=data[\"coord\"][\"lon\"],\n",
    "        latitud=data[\"coord\"][\"lat\"],\n",
    "        descripcion = translator.translate(data[\"weather\"][0][\"description\"], src='en', dest='es').text,\n",
    "        temperatura=float(data[\"main\"][\"temp\"]),  # Convertir a decimal utilizando float()\n",
    "        temperatura_max=float(data[\"main\"][\"temp_max\"]),\n",
    "        temperatura_min=float(data[\"main\"][\"temp_min\"]),\n",
    "        presion=float(data[\"main\"][\"pressure\"]),\n",
    "        humedad=\"{}%\".format(data[\"main\"][\"humidity\"]),\n",
    "        velocidad_viento=float(data[\"wind\"][\"speed\"]),\n",
    "        nombre=data[\"name\"],\n",
    "        zona_horaria=data[\"timezone\"],\n",
    "        pais=data[\"sys\"][\"country\"]\n",
    "    )\n",
    "\n",
    "    # Agregar el objeto Row a la lista datos_clima\n",
    "    datos_clima.append(dato_clima)\n",
    "    \n",
    "    # Definir el esquema del DataFrame\n",
    "esquema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), nullable=False),\n",
    "    StructField(\"longitud\", DoubleType(), nullable=True),\n",
    "    StructField(\"latitud\", DoubleType(), nullable=True),\n",
    "    StructField(\"descripcion\", StringType(), nullable=True),\n",
    "    StructField(\"temperatura\", DoubleType(), nullable=True),\n",
    "    StructField(\"temperatura_max\", DoubleType(), nullable=True),\n",
    "    StructField(\"temperatura_min\", DoubleType(), nullable=True),\n",
    "    StructField(\"presion\", DoubleType(), nullable=True),\n",
    "    StructField(\"humedad\", StringType(), nullable=True),\n",
    "    StructField(\"velocidad_viento\", DoubleType(), nullable=True),\n",
    "    StructField(\"nombre\", StringType(), nullable=True),\n",
    "    StructField(\"zona_horaria\", StringType(), nullable=True),\n",
    "    StructField(\"pais\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "# Crear el DataFrame utilizando el esquema\n",
    "dataframe = spark.createDataFrame(datos_clima, schema=esquema)\n",
    "\n",
    "# Mostrar el DataFrame por pantalla\n",
    "dataframe.show(dataframe.count(), truncate=False)\n",
    "\n",
    "\n",
    "# Datos de conexión a Amazon Redshift\n",
    "host = \"data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com\"\n",
    "port = 5439\n",
    "database = \"data-engineer-database\"\n",
    "user = \"mau_giovanetti_coderhouse\"\n",
    "password = \"5K6m1tR3h9\"\n",
    "schema = \"mau_giovanetti_coderhouse\"  # Nombre del esquema donde se creará la tabla\n",
    "\n",
    "# Crear la conexión a Amazon Redshift\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "# Crear el cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Crear la tabla en Amazon Redshift\n",
    "table_name = \"clima\"\n",
    "create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {}.{} (\n",
    "        ID INT PRIMARY KEY,\n",
    "        longitud DOUBLE PRECISION,\n",
    "        latitud DOUBLE PRECISION,\n",
    "        descripcion VARCHAR(255),\n",
    "        temperatura DOUBLE PRECISION,\n",
    "        temperatura_max DOUBLE PRECISION,\n",
    "        temperatura_min DOUBLE PRECISION,\n",
    "        presion DOUBLE PRECISION,\n",
    "        humedad VARCHAR(255),\n",
    "        velocidad_viento DOUBLE PRECISION,\n",
    "        nombre VARCHAR(255),\n",
    "        zona_horaria VARCHAR(255),\n",
    "        pais VARCHAR(255)\n",
    "    )\n",
    "\"\"\".format(schema, table_name)\n",
    "\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insertar los datos en la tabla\n",
    "for dato_clima in datos_clima:\n",
    "    id_clima = dato_clima.ID\n",
    "\n",
    "    # Verificar si los datos ya existen en la tabla\n",
    "    select_query = sql.SQL(\"\"\"\n",
    "        SELECT COUNT(*) FROM {}.{}\n",
    "        WHERE ID = %s\n",
    "    \"\"\").format(sql.Identifier(schema), sql.Identifier(table_name))\n",
    "\n",
    "    cursor.execute(select_query, (id_clima,))\n",
    "    result = cursor.fetchone()\n",
    "\n",
    "    if result[0] == 0:\n",
    "        # Los datos no existen, realizar la inserción\n",
    "        insert_query = sql.SQL(\"\"\"\n",
    "            INSERT INTO {}.{} (ID, longitud, latitud, descripcion, temperatura, temperatura_max, temperatura_min, presion, humedad, velocidad_viento, nombre, zona_horaria, pais)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\").format(sql.Identifier(schema), sql.Identifier(table_name))\n",
    "\n",
    "        cursor.execute(insert_query, dato_clima)\n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(\"Los datos con ID {} ya existen en la tabla.\".format(id_clima))\n",
    "\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"El proceso ha finalizado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
